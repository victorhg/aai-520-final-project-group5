{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ff4337-9948-4116-bd24-a848c71598f8",
   "metadata": {},
   "source": [
    "News Source:\n",
    "\n",
    "https://www.kaggle.com/datasets/notlucasp/financial-news-headlines/data\n",
    "\n",
    "Contents:\n",
    "\n",
    "Data scraped from CNBC contains the Headliness, last updated date, and the preview text of articles from the end of December 2017 to July 19th, 2020.\n",
    "\n",
    "Data scraped from the Guardian Business contains the Headliness and last updated date of articles from the end of December 2017 to July 19th, 2020 since the Guardian Business does not offer preview text.\n",
    "\n",
    "Data scraped from Reuters contains the Headliness, last updated date, and the preview text of articles from the end of March 2018 to July 19th, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5680aa6-39c9-43bf-a8da-d03f0c00863d",
   "metadata": {},
   "source": [
    "Sentiment via TextBlob:\n",
    "\n",
    "not an ML-trained model like BERT or FinBERT. It’s dictionary-based → works okay for simple financial headlines but may miss sarcasm, jargon, or complex finance tone.\n",
    "\n",
    "# Financial News Agentic AI Pipeline Summary\n",
    "\n",
    "### 1. Dataset Preparation\n",
    "- Load multiple news datasets (CNBC, Guardian, Reuters).\n",
    "- Handle differences in columns (e.g., some may not have `Description`).\n",
    "\n",
    "### 2. Text Preprocessing\n",
    "- Lowercase all text.\n",
    "- Keep alphanumeric characters only.\n",
    "- Remove stopwords.\n",
    "- Output: `cleaned_text`.\n",
    "\n",
    "### 3. Topic Tagging\n",
    "- Text-based classification of each headline:\n",
    "  - `earnings`: earnings, revenue, EPS, quarter\n",
    "  - `market`: stock, shares, price\n",
    "  - `macro`: fed, inflation, GDP, rate\n",
    "  - `general`: default\n",
    "\n",
    "### 4. Sentiment Analysis\n",
    "- Use **TextBlob** model to compute polarity:\n",
    "  - `positive` if polarity > 0.1  \n",
    "  - `negative` if polarity < -0.1  \n",
    "  - `neutral` otherwise\n",
    "- Output: sentiment label per headline.\n",
    "\n",
    "### 5. Routing to Specialist Agents\n",
    "- **Earnings agent:** receives topic + sentiment → `eps_signal`, `revenue_signal`\n",
    "- **Market agent:** topic + sentiment → `market_signal`\n",
    "- **Macro agent:** topic + sentiment → `macro_signal`\n",
    "- **General agent:** topic + sentiment → `general_signal` (always 0)\n",
    "- Agents are **rule-based**; only TextBlob sentiment is model-based.\n",
    "\n",
    "### 6. Tesla Filtering\n",
    "- Select headlines mentioning `\"Tesla\"` in `Headlines` or `Description` (if exists).\n",
    "\n",
    "### 7. Weighted Aggregation\n",
    "- Combine all agent outputs for Tesla headlines.\n",
    "- Signals are multiplied by predefined weights:\n",
    "  - `eps_signal` → weight 3  \n",
    "  - `revenue_signal` → weight 2  \n",
    "  - `market_signal` → weight 2  \n",
    "  - `macro_signal` → weight 1  \n",
    "  - `general_signal` → weight 0\n",
    "\n",
    "### 8. Trade Suggestion\n",
    "- Sum weighted signals to compute total score.\n",
    "- Map total score → trade action:\n",
    "  - Total ≥ 3 → **BUY**\n",
    "  - Total ≤ -2 → **SELL**\n",
    "  - Otherwise → **HOLD**\n",
    "\n",
    "### 9. Reporting\n",
    "- Print per dataset:\n",
    "  - Number of Tesla headlines\n",
    "  - Aggregated trade suggestion (BUY/HOLD/SELL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd005694-d746-4fc9-825c-c6c30ccbd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc64f87d-b358-445c-aab2-49b7332198b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache path: C:\\Users\\Administrator\\.cache\\kagglehub\\datasets\\notlucasp\\financial-news-headlines\\versions\\2\n",
      "Files moved to: C:\\Users\\Administrator\\Documents\\GitHub\\aai-520-final-project-group5\\news-datasets\\kaggle-headlines-data\n",
      "Number of files: 3\n",
      "Filenames: ['cnbc_headlines.csv', 'guardian_headlines.csv', 'reuters_headlines.csv']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Setup\n",
    "# ------------------------\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# ------------------------\n",
    "# Download dataset (cached)\n",
    "# ------------------------\n",
    "path = kagglehub.dataset_download(\"notlucasp/financial-news-headlines\")\n",
    "print(\"Cache path:\", path)\n",
    "\n",
    "# ------------------------\n",
    "# Define target folder\n",
    "# ------------------------\n",
    "target_dir = os.path.abspath(os.path.join(\"..\", \"news-datasets\", \"kaggle-headlines-data\"))\n",
    "if os.path.exists(target_dir):\n",
    "    shutil.rmtree(target_dir)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# ------------------------\n",
    "# Copy all files from versioned folder to target\n",
    "# ------------------------\n",
    "for item in os.listdir(path):\n",
    "    src_file = os.path.join(path, item)\n",
    "    if os.path.isfile(src_file):\n",
    "        shutil.copy(src_file, target_dir)\n",
    "\n",
    "# ------------------------\n",
    "# Show where files were moved, count, and filenames\n",
    "# ------------------------\n",
    "files = os.listdir(target_dir)\n",
    "print(\"Files moved to:\", target_dir)\n",
    "print(\"Number of files:\", len(files))\n",
    "print(\"Filenames:\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a017276-6a45-40e3-8c32-a4ac1f168f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnbc_headlines.csv\n",
      "                                          Headlines                           Time                                         Description\n",
      "Jim Cramer: A better way to invest in the Covid-19…  7:51  PM ET Fri, 17 July 2020 \"Mad Money\" host Jim Cramer recommended buying fou…\n",
      "    Cramer's lightning round: I would own Teradyne…  7:33  PM ET Fri, 17 July 2020 \"Mad Money\" host Jim Cramer rings the lightning ro…\n",
      "                                                  …                            NaN                                                   …\n",
      "Cramer's week ahead: Big week for earnings, even b…  7:25  PM ET Fri, 17 July 2020 \"We'll pay more for the earnings of the non-Covid …\n",
      "IQ Capital CEO Keith Bliss says tech and healthcar…  4:24  PM ET Fri, 17 July 2020 Keith Bliss, IQ Capital CEO, joins \"Closing Bell\" …\n"
     ]
    }
   ],
   "source": [
    "# Load cnbc CSV into dataframe\n",
    "file_path = os.path.join(target_dir, files[0])\n",
    "cnbc_raw_df = pd.read_csv(file_path)\n",
    "\n",
    "# Truncate text for display\n",
    "cnbc_display = cnbc_raw_df.copy()\n",
    "cnbc_display[\"Headlines\"] = cnbc_display[\"Headlines\"].fillna(\"\").str[:50] + \"…\"\n",
    "if \"Description\" in cnbc_display.columns:\n",
    "    cnbc_display[\"Description\"] = cnbc_display[\"Description\"].fillna(\"\").str[:50] + \"…\"\n",
    "\n",
    "# Print truncated dataframe\n",
    "print(files[0])\n",
    "print(cnbc_display.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb7aad7-fd6a-4277-bc2b-6d681aef7fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3080 entries, 0 to 3079\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Headlines    2800 non-null   object\n",
      " 1   Time         2800 non-null   object\n",
      " 2   Description  2800 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 72.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cnbc_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "747d2924-370a-479e-9aaf-157a511bade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guardian_headlines.csv\n",
      "     Time                                              Headlines\n",
      "18-Jul-20      Johnson is asking Santa for a Christmas recovery…\n",
      "18-Jul-20    ‘I now fear the worst’: four grim tales of working…\n",
      "18-Jul-20    Five key areas Sunak must tackle to serve up econo…\n",
      "18-Jul-20    Covid-19 leaves firms ‘fatally ill-prepared’ for n…\n",
      "18-Jul-20 The Week in Patriarchy  \\n\\n\\n  Bacardi's 'lady vodka…\n"
     ]
    }
   ],
   "source": [
    "# Load guardian CSV into dataframe\n",
    "file_path = os.path.join(target_dir, files[1])\n",
    "guardian_raw_df = pd.read_csv(file_path)\n",
    "\n",
    "# Truncate text for display\n",
    "guardian_display = guardian_raw_df.copy()\n",
    "guardian_display[\"Headlines\"] = guardian_display[\"Headlines\"].fillna(\"\").str[:50] + \"…\"\n",
    "\n",
    "# Print truncated dataframe\n",
    "print(files[1])\n",
    "print(guardian_display.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d205943-119d-48fe-bb08-5da0c8a8ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17800 entries, 0 to 17799\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Time       17800 non-null  object\n",
      " 1   Headlines  17800 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 278.3+ KB\n"
     ]
    }
   ],
   "source": [
    "guardian_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188ebdc9-713e-41b4-905a-46300ea44a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reuters_headlines.csv\n",
      "                                          Headlines        Time                                         Description\n",
      "TikTok considers London and other locations for he… Jul 18 2020 TikTok has been in discussions with the UK governm…\n",
      "Disney cuts ad spending on Facebook amid growing b… Jul 18 2020 Walt Disney  has become the latest company to slas…\n",
      "Trail of missing Wirecard executive leads to Belar… Jul 18 2020 Former Wirecard  chief operating officer Jan Marsa…\n",
      "Twitter says attackers downloaded data from up to … Jul 18 2020 Twitter Inc said on Saturday that hackers were abl…\n",
      "U.S. Republicans seek liability protections as cor… Jul 17 2020 A battle in the U.S. Congress over a new coronavir…\n"
     ]
    }
   ],
   "source": [
    "# Load reuters CSV into dataframe\n",
    "file_path = os.path.join(target_dir, files[2])\n",
    "reuters_raw_df = pd.read_csv(file_path)\n",
    "\n",
    "# Truncate to first 50 characters directly using .str\n",
    "reuters_display = reuters_raw_df.copy()\n",
    "reuters_display[\"Headlines\"] = reuters_display[\"Headlines\"].str[:50] + \"…\"\n",
    "if \"Description\" in reuters_display.columns:\n",
    "    reuters_display[\"Description\"] = reuters_display[\"Description\"].str[:50] + \"…\"\n",
    "\n",
    "print(files[2])\n",
    "print(reuters_display.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d338fe6-f585-445d-8034-3ee56c28de83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32770 entries, 0 to 32769\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Headlines    32770 non-null  object\n",
      " 1   Time         32770 non-null  object\n",
      " 2   Description  32770 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 768.2+ KB\n"
     ]
    }
   ],
   "source": [
    "reuters_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26c111b9-30a3-42a8-8f9c-abe57faab332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset: cnbc --- Total Tesla headlines count: 36 Trade suggestion: SELL ---\n",
      "Non-general agent weighted scores per article:\n",
      "    Article 12: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 17: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 20: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 25: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 31: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 32: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "\n",
      "\n",
      "--- Dataset: guardian --- Total Tesla headlines count: 78 Trade suggestion: BUY ---\n",
      "Non-general agent weighted scores per article:\n",
      "    Article 26: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 38: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 45: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 59: Agent: macro | Weighted Article Score: -1 | Agent Output: {'macro_signal': -1}\n",
      "\n",
      "\n",
      "--- Dataset: reuters --- Total Tesla headlines count: 699 Trade suggestion: BUY ---\n",
      "Non-general agent weighted scores per article:\n",
      "    Article 18: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 23: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 39: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 46: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 66: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 85: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 101: Agent: macro | Weighted Article Score: 1 | Agent Output: {'macro_signal': 1}\n",
      "    Article 135: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 137: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 141: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 148: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 159: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 176: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 235: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 311: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 317: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 318: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 328: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 350: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 374: Agent: earnings | Weighted Article Score: 5 | Agent Output: {'eps_signal': 1, 'revenue_signal': 1}\n",
      "    Article 457: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 530: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 558: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 569: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 600: Agent: market | Weighted Article Score: 2 | Agent Output: {'market_signal': 1}\n",
      "    Article 641: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 666: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "    Article 692: Agent: market | Weighted Article Score: -2 | Agent Output: {'market_signal': -1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# Define company to filter\n",
    "# ------------------------\n",
    "company_name = \"Tesla\"  # Change this to filter a different company\n",
    "\n",
    "# ------------------------\n",
    "# Define datasets dictionary\n",
    "# ------------------------\n",
    "datasets = {\n",
    "    \"cnbc\": cnbc_raw_df,\n",
    "    \"guardian\": guardian_raw_df,\n",
    "    \"reuters\": reuters_raw_df\n",
    "}\n",
    "\n",
    "# ------------------------\n",
    "# Function: Preprocessing + Tagging\n",
    "# ------------------------\n",
    "def preprocess_and_tag(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    # 2. Keep alphanumeric only\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # 3. Remove stopwords\n",
    "    tokens = [w for w in text.split() if w not in stop_words]\n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    # 4. Topic tagging\n",
    "    if any(word in cleaned_text for word in [\"earnings\", \"quarter\", \"revenue\", \"eps\"]):\n",
    "        topic = \"earnings\"\n",
    "    elif any(word in cleaned_text for word in [\"market\", \"stock\", \"shares\", \"price\"]):\n",
    "        topic = \"market\"\n",
    "    elif any(word in cleaned_text for word in [\"fed\", \"inflation\", \"gdp\", \"rate\"]):\n",
    "        topic = \"macro\"\n",
    "    else:\n",
    "        topic = \"general\"\n",
    "    \n",
    "    # 5. Sentiment tagging using TextBlob\n",
    "    polarity = TextBlob(cleaned_text).sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        sentiment = \"positive\"\n",
    "    elif polarity < -0.1:\n",
    "        sentiment = \"negative\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "    \n",
    "    return cleaned_text, topic, sentiment\n",
    "\n",
    "# ------------------------\n",
    "# Specialist Agent Functions\n",
    "# ------------------------\n",
    "def earnings_agent(text, sentiment):\n",
    "    eps_signal = 1 if sentiment == \"positive\" else 0\n",
    "    revenue_signal = 1 if sentiment == \"positive\" else 0\n",
    "    return {\"eps_signal\": eps_signal, \"revenue_signal\": revenue_signal}\n",
    "\n",
    "def market_agent(text, sentiment):\n",
    "    market_signal = 1 if sentiment == \"positive\" else (-1 if sentiment == \"negative\" else 0)\n",
    "    return {\"market_signal\": market_signal}\n",
    "\n",
    "def macro_agent(text, sentiment):\n",
    "    macro_signal = 1 if sentiment == \"positive\" else (-1 if sentiment == \"negative\" else 0)\n",
    "    return {\"macro_signal\": macro_signal}\n",
    "\n",
    "def general_agent(text, sentiment):\n",
    "    return {\"general_signal\": 0}\n",
    "\n",
    "# ------------------------\n",
    "# Routing Function\n",
    "# ------------------------\n",
    "def route_to_agent(row):\n",
    "    topic = row[\"topic\"]\n",
    "    sentiment = row[\"sentiment\"]\n",
    "    text = row[\"cleaned_text\"]\n",
    "    \n",
    "    if topic == \"earnings\":\n",
    "        return earnings_agent(text, sentiment)\n",
    "    elif topic == \"market\":\n",
    "        return market_agent(text, sentiment)\n",
    "    elif topic == \"macro\":\n",
    "        return macro_agent(text, sentiment)\n",
    "    else:\n",
    "        return general_agent(text, sentiment)\n",
    "\n",
    "# ------------------------\n",
    "# Function: Full processing for a single dataset with weighted scores and agent labels\n",
    "# ------------------------\n",
    "def process_dataset_company_with_agent_scores(df, label, company_name):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Preprocess Headlines\n",
    "    df[[\"cleaned_text\", \"topic\", \"sentiment\"]] = df[\"Headlines\"].apply(\n",
    "        lambda x: pd.Series(preprocess_and_tag(str(x)))\n",
    "    )\n",
    "    \n",
    "    # Route to agents and store agent type\n",
    "    agent_names = []\n",
    "    agent_outputs = []\n",
    "    for idx, row in df.iterrows():\n",
    "        output = route_to_agent(row)\n",
    "        agent_outputs.append(output)\n",
    "        # Determine agent name from topic\n",
    "        agent_names.append(row[\"topic\"])\n",
    "    \n",
    "    df[\"agent_output\"] = agent_outputs\n",
    "    df[\"agent_name\"] = agent_names\n",
    "    \n",
    "    # Filter company-specific headlines\n",
    "    if \"Description\" in df.columns:\n",
    "        company_df = df[\n",
    "            df[\"Headlines\"].str.contains(company_name, case=False, na=False) |\n",
    "            df[\"Description\"].str.contains(company_name, case=False, na=False)\n",
    "        ]\n",
    "    else:\n",
    "        company_df = df[\n",
    "            df[\"Headlines\"].str.contains(company_name, case=False, na=False)\n",
    "        ]\n",
    "    \n",
    "    # Define weights\n",
    "    # ------------------------\n",
    "    # The weights reflect the relative importance of each agent's signal to the final trade suggestion:\n",
    "    # - eps_signal (3): EPS is a key indicator of company profitability, most impactful on buy/sell decisions.\n",
    "    # - revenue_signal (2): Revenue trends are important but slightly less critical than EPS.\n",
    "    # - market_signal (2): Overall stock/market sentiment influences short-term price moves, similar importance to revenue.\n",
    "    # - macro_signal (1): Macro news (Fed, GDP, inflation) has an indirect effect, so lower weight.\n",
    "    # - general_signal (0): General or uncategorized news has minimal predictive value, so weight is 0.\n",
    "    weights = {\n",
    "        \"eps_signal\": 3,\n",
    "        \"revenue_signal\": 2,\n",
    "        \"market_signal\": 2,\n",
    "        \"macro_signal\": 1,\n",
    "        \"general_signal\": 0\n",
    "    }\n",
    "    \n",
    "    # Compute weighted scores per row\n",
    "    weighted_scores = []\n",
    "    for out in company_df[\"agent_output\"]:\n",
    "        score = sum(value * weights.get(key, 0) for key, value in out.items())\n",
    "        weighted_scores.append(score)\n",
    "    \n",
    "    # Aggregate to determine trade signal\n",
    "    total_score = sum(weighted_scores)\n",
    "    if total_score >= 3:\n",
    "        trade_signal = \"BUY\"\n",
    "    elif total_score <= -2:\n",
    "        trade_signal = \"SELL\"\n",
    "    else:\n",
    "        trade_signal = \"HOLD\"\n",
    "    \n",
    "    # ------------------------\n",
    "    # Print dataset-specific results\n",
    "    # ------------------------\n",
    "    print(f\"--- Dataset: {label} --- Total {company_name} headlines count: {len(company_df)} Trade suggestion: {trade_signal} ---\")\n",
    "    print(\"Non-general agent weighted scores per article:\")\n",
    "    for idx, (row, score) in enumerate(zip(company_df.itertuples(), weighted_scores), start=1):\n",
    "        # Only show outputs that are not from the general agent\n",
    "        filtered_out = {k: v for k, v in row.agent_output.items() if k != \"general_signal\" and v != 0}\n",
    "        if filtered_out:\n",
    "            print(f\"    Article {idx}: Agent: {row.agent_name} | Weighted Article Score: {score} | Agent Output: {filtered_out}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ------------------------\n",
    "# Process all datasets for the company with agent labels and weighted scores\n",
    "# ------------------------\n",
    "processed_dfs_with_agent_scores = {}\n",
    "for label, df in datasets.items():\n",
    "    processed_dfs_with_agent_scores[label] = process_dataset_company_with_agent_scores(df, label, company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1ded9-93b8-4c13-84d3-d38997a81625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
